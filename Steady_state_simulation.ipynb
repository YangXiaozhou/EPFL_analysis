{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandapower as pp\n",
    "import pandapower.networks\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import math\n",
    "import time\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rename(network):\n",
    "    line_name = []\n",
    "    bus_name = []\n",
    "    for i in (network.line.index.values+1):\n",
    "        line_name.append('line_'+str(i))\n",
    "    \n",
    "    for j in network.bus.name.values:\n",
    "        bus_name.append('bus_'+str(j))\n",
    "    \n",
    "    # Rename lines: i.e. 'line_1'\n",
    "    network.line.name=line_name\n",
    "    \n",
    "    # Rename bus: i.e. 'bus_1'\n",
    "    network.bus.name=bus_name\n",
    "    pass\n",
    "\n",
    "def record_pmu_data(network, pmu_index):\n",
    "    \n",
    "    pmu_0_va_degree.append(network.res_bus.loc[pmu_index[0]].va_degree)\n",
    "    pmu_0_vm_pu.append(network.res_bus.loc[pmu_index[0]].vm_pu)\n",
    "    \n",
    "    pmu_1_va_degree.append(network.res_bus.loc[pmu_index[1]].va_degree)\n",
    "    pmu_1_vm_pu.append(network.res_bus.loc[pmu_index[1]].vm_pu)\n",
    "    \n",
    "    pmu_2_va_degree.append(network.res_bus.loc[pmu_index[2]].va_degree)\n",
    "    pmu_2_vm_pu.append(network.res_bus.loc[pmu_index[2]].vm_pu)\n",
    "\n",
    "def change_loads(network, loads_at_time_t):\n",
    "    for i in range(network.load.shape[0]):\n",
    "        network.load.p_kw[i] = loads_at_time_t[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "pmu_location = [23, 26, 29]\n",
    "pmu_index = [i-1 for i in pmu_location] # To conform with data format in the case, 0-start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean = 300000\n",
    "std = 10000\n",
    "samples_per_second = 60\n",
    "#lines_to_be_outed = [4, 14, 34]\n",
    "lines_to_be_outed = [1, 4, 7, 10, 14, 18, 21, 24, 30, 34]\n",
    "samples_per_line = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Outed lines:  [1, 4, 7, 10, 14, 18, 21, 24, 30, 34]\n",
      "Number of outed lines simulated: 10\n",
      "Number of simulation per line: 100\n",
      "PMU records 60 samples per second\n",
      "Time taken: 2805.402s\n"
     ]
    }
   ],
   "source": [
    "training_data = pd.DataFrame()\n",
    "start_time = time.time()\n",
    "\n",
    "for line in lines_to_be_outed:\n",
    "    for line_sample in range(samples_per_line):\n",
    "        \n",
    "        # Set up data structure for recording\n",
    "        pmu_0_va_degree = []\n",
    "        pmu_1_va_degree = []\n",
    "        pmu_2_va_degree = []\n",
    "\n",
    "        pmu_0_vm_pu = []\n",
    "        pmu_1_vm_pu = []\n",
    "        pmu_2_vm_pu = []\n",
    "\n",
    "        pmu_data = pd.DataFrame()\n",
    "        for pmu_loc in range(len(pmu_location)):\n",
    "            pmu_data['pmu_'+str(pmu_loc)+'_va_degree'] = []\n",
    "            pmu_data['pmu_'+str(pmu_loc)+'_vm_pu'] = []\n",
    "\n",
    "            \n",
    "        # Set up power network\n",
    "        net_39 = pandapower.networks.case39()\n",
    "        rename(net_39)\n",
    "        \n",
    "        # Generate a new set of loads for one outage instance\n",
    "        loads = pd.DataFrame()\n",
    "        for load_index in range(net_39.load.shape[0]):\n",
    "            name = 'load_'+str(load_index)\n",
    "            loads[name] = np.random.normal(loc=mean, scale=std, size=samples_per_second)\n",
    "        \n",
    "        # Run the power network\n",
    "        pp.runpp(net_39)\n",
    "\n",
    "        # Record data, for a PMU with 60 sps\n",
    "        for timestep in range(samples_per_second):\n",
    "            change_loads(net_39, loads.loc[timestep])\n",
    "            pp.runpp(net_39)\n",
    "            record_pmu_data(net_39, pmu_index)\n",
    "\n",
    "        pmu_data = pd.DataFrame(list(zip(pmu_0_va_degree, pmu_0_vm_pu, \n",
    "                                    pmu_1_va_degree, pmu_1_vm_pu, pmu_2_va_degree, \n",
    "                                    pmu_2_vm_pu)), columns=pmu_data.columns)\n",
    "\n",
    "        # Setting a line out of service\n",
    "        line_number = line\n",
    "        net_39.line.in_service.loc[line_number-1] = False\n",
    "        net_39.line.loc[line_number-1]\n",
    "\n",
    "        # Record data after the line outage\n",
    "        for timestep in range(samples_per_second):\n",
    "            change_loads(net_39, loads.loc[timestep])\n",
    "            pp.runpp(net_39)\n",
    "            record_pmu_data(net_39, pmu_index)\n",
    "\n",
    "        pmu_data = pd.DataFrame(list(zip(pmu_0_va_degree, pmu_0_vm_pu, \n",
    "                                    pmu_1_va_degree, pmu_1_vm_pu, pmu_2_va_degree, \n",
    "                                    pmu_2_vm_pu)), columns=pmu_data.columns)\n",
    "\n",
    "\n",
    "        fft_pmu0 = np.fft.fft(pmu_data.pmu_0_va_degree)\n",
    "        fft_pmu1 = np.fft.fft(np.asarray(pmu_data.pmu_1_va_degree)-np.asarray(pmu_data.pmu_0_va_degree))\n",
    "        fft_pmu2 = np.fft.fft(np.asarray(pmu_data.pmu_2_va_degree)-np.asarray(pmu_data.pmu_0_va_degree))\n",
    "\n",
    "\n",
    "        imag_pmu0 = fft_pmu0.imag.tolist()\n",
    "        imag_pmu1 = fft_pmu1.imag.tolist()\n",
    "        imag_pmu2 = fft_pmu2.imag.tolist()\n",
    "\n",
    "        predictor = imag_pmu0[60:]\n",
    "        predictor.append(imag_pmu0[60] - imag_pmu0[59])\n",
    "        predictor.extend(imag_pmu1[60:])\n",
    "        predictor.append(imag_pmu1[60] - imag_pmu1[59])\n",
    "        predictor.extend(imag_pmu2[60:])\n",
    "        predictor.append(imag_pmu2[60] - imag_pmu2[59])\n",
    "\n",
    "        training = predictor\n",
    "        training.extend([line_number])\n",
    "        training_data['line_'+str(line)+'_'+str(line_sample)] = pd.Series(training)\n",
    "\n",
    "duration = time.time() - start_time\n",
    "\n",
    "print('Outed lines: ', lines_to_be_outed)\n",
    "print('Number of outed lines simulated: %.f' %len(lines_to_be_outed))\n",
    "print('Number of simulation per line: %.f' %samples_per_line)\n",
    "print('PMU records %.f samples per second' %samples_per_second)\n",
    "print('Time taken: %.3fs' %duration)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.32       1.         0.78125    0.39130435 1.         0.86153846\n",
      " 0.82191781 0.6        0.96774194 1.        ]\n",
      "[0.39285714 1.         0.8115942  0.3255814  1.         0.95238095\n",
      " 0.82191781 0.75471698 0.95238095 1.        ]\n",
      "[0.375      1.         0.69565217 0.35555556 1.         0.82539683\n",
      " 0.82191781 0.65517241 0.9375     1.        ]\n",
      "[0.47058824 1.         0.8        0.27906977 1.         0.95238095\n",
      " 0.8        0.59259259 0.9375     1.        ]\n",
      "[0.40816327 1.         0.80597015 0.33333333 1.         0.92063492\n",
      " 0.85714286 0.74074074 0.86956522 1.        ]\n"
     ]
    }
   ],
   "source": [
    "train_df = training_data.transpose()\n",
    "\n",
    "train_df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# load data\n",
    "X = train_df.iloc[:,:-1]\n",
    "y = train_df.iloc[:,-1:]\n",
    "\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn import linear_model\n",
    "\n",
    "logreg = linear_model.LogisticRegression(C=1e5, penalty='l1', solver='saga', multi_class='multinomial')\n",
    "\n",
    "sss = StratifiedShuffleSplit(n_splits=5, test_size=0.3)\n",
    "for train, test in sss.split(X, y):\n",
    "    logreg_fit = logreg.fit(X.loc[train],np.ravel(y.loc[train])) \n",
    "    y_pred = logreg_fit.predict(X.loc[test])\n",
    "    print(f1_score(np.ravel(y.loc[test]), y_pred, average=None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = [[0.32,1.,0.78125,0.39130435, 1.  ,0.86153846,0.82191781, 0.6   ,     0.96774194, 1.        ],\n",
    "[0.39285714,1.,0.8115942 , 0.3255814 , 1.   ,0.95238095,0.82191781, 0.75471698, 0.95238095 ,1.        ],\n",
    "[0.375,1.,0.69565217, 0.35555556 ,1.   ,0.82539683,0.82191781 ,0.65517241, 0.9375   ,  1.        ],\n",
    "[0.47058824,1.,0.8  ,      0.27906977 ,1.  ,0.95238095,0.8   ,     0.59259259, 0.9375    , 1.        ],\n",
    "[0.40816327,1.,0.80597015 ,0.33333333, 1.   ,0.92063492,0.85714286 ,0.74074074, 0.86956522 ,1.        ]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 4, 7, 10, 14, 18, 21, 24, 30, 34]\n",
      "[0.39332173 1.         0.7788933  0.33696888 1.         0.90246642\n",
      " 0.82457926 0.66864454 0.93293762 1.        ]\n"
     ]
    }
   ],
   "source": [
    "print(lines_to_be_outed)\n",
    "print(np.mean(results, axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.to_csv('training_10_lines_100_samples_0325.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
